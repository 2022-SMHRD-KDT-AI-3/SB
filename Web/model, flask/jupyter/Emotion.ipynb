{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pafy\n",
      "  Downloading pafy-0.5.5-py2.py3-none-any.whl (35 kB)\n",
      "Collecting youtube-dl\n",
      "  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n",
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "Collecting decorator<5.0,>=4.0.2\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting tqdm<5.0,>=4.11.2\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\smhrd\\anaconda3\\envs\\zizi\\lib\\site-packages (from moviepy) (2.28.0)\n",
      "Collecting proglog<=1.0.0\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\smhrd\\anaconda3\\envs\\zizi\\lib\\site-packages (from moviepy) (1.21.5)\n",
      "Collecting imageio<3.0,>=2.5\n",
      "  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
      "Collecting imageio_ffmpeg>=0.2.0\n",
      "  Downloading imageio_ffmpeg-0.4.7-py3-none-win_amd64.whl (22.6 MB)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\smhrd\\anaconda3\\envs\\zizi\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (9.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\smhrd\\anaconda3\\envs\\zizi\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\smhrd\\anaconda3\\envs\\zizi\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smhrd\\anaconda3\\envs\\zizi\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\smhrd\\anaconda3\\envs\\zizi\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\smhrd\\anaconda3\\envs\\zizi\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.4)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py): started\n",
      "  Building wheel for moviepy (setup.py): finished with status 'done'\n",
      "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110743 sha256=c1ff8dfb1346781453b358e69805bba07f00591a7af8f776da1868c243882acc\n",
      "  Stored in directory: c:\\users\\smhrd\\appdata\\local\\pip\\cache\\wheels\\56\\dc\\2b\\9cd600d483c04af3353d66623056fc03faed76b7518faae4df\n",
      "Successfully built moviepy\n",
      "Installing collected packages: tqdm, proglog, imageio-ffmpeg, imageio, decorator, youtube-dl, pafy, moviepy\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed decorator-4.4.2 imageio-2.19.3 imageio-ffmpeg-0.4.7 moviepy-1.0.3 pafy-0.5.5 proglog-0.1.10 tqdm-4.64.0 youtube-dl-2021.12.17\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치하기\n",
    "!pip install pafy youtube-dl moviepy opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import *\n",
    "from collections import deque\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정하기\n",
    "seed_constant = 99\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 크기 설정하기\n",
    "image_height, image_width = 128, 128\n",
    "\n",
    "# 최대 프레임 수 설정하기\n",
    "max_images_per_class = 600\n",
    "\n",
    "dataset_directory = '분류된 폴더가 있는 경로를 입력하면 됨'\n",
    "classes_list = ['불안, 슬픔, 공포', '편안, 안정, 행복', '화남, 불쾌, 공격성'] # os.listdir로 불러와도 됨\n",
    "\n",
    "model_output_size = len(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프레임 추출하기\n",
    "def frames_extraction(video_path):\n",
    "    \n",
    "    frames_list = []\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while True:\n",
    "        success, frame = video_reader.read() \n",
    "        \n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        normalized_frame = resized_frame / 255\n",
    "        frames_list.append(normalized_frame)\n",
    "    \n",
    "    video_reader.release()\n",
    "\n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성하기\n",
    "def create_dataset():\n",
    "\n",
    "    temp_features = []\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        files_list = os.listdir(os.path.join(dataset_directory, class_name))\n",
    "        \n",
    "        for file_name in files_list:\n",
    "            video_file_path = os.path.join(dataset_directory, class_name, file_name)\n",
    "            frames = frames_extraction(video_file_path)\n",
    "            temp_features.extend(frames)        \n",
    "       \n",
    "        features.extend(random.sample(temp_features, max_images_per_class))\n",
    "        labels.extend([class_index] * max_images_per_class)\n",
    "        temp_features.clear()\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    "\n",
    "    return features, labels\n",
    "\n",
    "features, labels = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_labels = to_categorical(labels)\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, shuffle = True, random_state = seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성하기(VGG16 모델 전이학습)\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights = \"imagenet\", include_top = False, input_shape = (image_height, image_width, 3))\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(conv_base)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units = 32, activation = \"relu\"))\n",
    "    model.add(Dense(units = 64, activation = \"relu\"))\n",
    "    model.add(Dense(units = 128, activation = \"relu\"))\n",
    "    model.add(Dense(units = 128, activation = \"relu\"))\n",
    "    model.add(Dense(units = 64, activation = \"relu\"))\n",
    "    model.add(Dense(units = 32, activation = \"relu\"))\n",
    "    model.add(Dense(units = model_output_size, activation = \"softmax\")) \n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "model_save_dir = \"모델을 저장할 폴더의 경로를 입력하면 됨\"\n",
    "filepath = model_save_dir + \"model_acc_{accuracy:.3f}_vacc_{val_accuracy:.3f}_loss_{loss:.3f}_vloss_{val_loss:.3f}.hdf5\"\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath = filepath, monitor = 'val_accuracy', save_best_only = True)    \n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, mode = 'max', restore_best_weights = True)\n",
    "\n",
    "model_training_history = model.fit(x = features_train, y = labels_train, epochs = 100, batch_size = 10 , shuffle = True, validation_data = (features_test, labels_test), callbacks = [model_checkpoint_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오고 동영상 분석하기\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"불러올 모델 파일의 경로를 입력하면 됨\")\n",
    "\n",
    "def make_average_predictions(video_file_path, predictions_frames_count):\n",
    "    \n",
    "    predicted_labels_probabilities_np = np.zeros((predictions_frames_count, model_output_size), dtype = np.float)\n",
    "\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    skip_frames_window = video_frames_count // predictions_frames_count\n",
    "\n",
    "    for frame_counter in range(predictions_frames_count):\n",
    "        \n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "        _ , frame = video_reader.read() \n",
    "\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        predicted_labels_probabilities = model.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
    "        predicted_labels_probabilities_np[frame_counter] = predicted_labels_probabilities\n",
    "\n",
    "    predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "    predicted_labels_probabilities_averaged_sorted_indexes = np.argsort(predicted_labels_probabilities_averaged)[::-1]\n",
    "    \n",
    "    dic_res = {} # 최종 결과값을 저장할 딕셔너리를 생성함\n",
    "    \n",
    "    for predicted_label in predicted_labels_probabilities_averaged_sorted_indexes:\n",
    "\n",
    "        predicted_class_name = classes_list[predicted_label]\n",
    "        predicted_probability = predicted_labels_probabilities_averaged[predicted_label]\n",
    "\n",
    "        dic_res[predicted_class_name] = predicted_probability\n",
    "\n",
    "    video_reader.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "CLASS NAME: 화남, 불쾌, 공격성   AVERAGED PROBABILITY: 0.8540238777796427\n",
      "{'화남, 불쾌, 공격성': 0.8540238777796427}\n",
      "CLASS NAME: 편안, 안정, 행복   AVERAGED PROBABILITY: 0.11335821500979364\n",
      "{'화남, 불쾌, 공격성': 0.8540238777796427, '편안, 안정, 행복': 0.11335821500979364}\n",
      "CLASS NAME: 불안, 슬픔, 공포   AVERAGED PROBABILITY: 0.0326179020810135\n",
      "{'화남, 불쾌, 공격성': 0.8540238777796427, '편안, 안정, 행복': 0.11335821500979364, '불안, 슬픔, 공포': 0.0326179020810135}\n"
     ]
    }
   ],
   "source": [
    "input_video_file_path = \"분석할 동영상 파일의 경로를 입력하면 됨\"\n",
    "make_average_predictions(input_video_file_path, 60) # 결과는 딕셔너리 형태로 반환됨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('zizi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac46d6d00e3595b56614442942c0c0bee95225b865cfc1531d0a55df256ffdd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
