{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow : https://www.tensorflow.org/install/source_windows?hl=ko#gpu\n",
    "# Pytorch : https://pytorch.org/get-started/locally/\n",
    "\n",
    "# 가이드라인 : https://doitgrow.com/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18162600721740017440\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6943080448\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8701230724418798165\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices()) # 장치 정보가 출력되어야 정상임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "gpu_device_name >>  /device:GPU:0\n",
      "Num GPUs Available >>  1\n",
      "cuda available >>  True\n",
      "cuda number of device >> 1\n",
      "cuda device_name(0) >> NVIDIA GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Tensorflow 설치 확인하기\n",
    "    print(tf.__version__)\n",
    "    print(\"gpu_device_name >> \", tf.test.gpu_device_name())\n",
    "    print(\"Num GPUs Available >> \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "    # Pytorch 설치 확인하기\n",
    "    isAvailable= torch.cuda.is_available()\n",
    "    print(\"cuda available >> \",  isAvailable)\n",
    "    if isAvailable:\n",
    "        count= torch.cuda.device_count()\n",
    "        print(\"cuda number of device >>\", count)\n",
    "        for index in range(0,count):\n",
    "            print(\"cuda device_name(0) >>\", torch.cuda.get_device_name(0))\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed7c606c1b398c5cd7cfd4247dcdbd6c4f727a97faf88aecf865baf46f72bc17"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('zizi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
